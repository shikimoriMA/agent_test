llama-cpp-python>=0.3.0
mcp>=0.0.7
huggingface_hub>=0.23.0
